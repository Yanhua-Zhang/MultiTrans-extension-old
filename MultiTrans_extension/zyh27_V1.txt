Script started on 2023-07-05 16:15:39+08:00 [TERM="screen.xterm-256color" TTY="/dev/pts/29" COLUMNS="189" LINES="9"]
Wed Jul  5 16:15:39 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.76       Driver Version: 515.76       CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:18:00.0 Off |                  N/A |
| 30%   36C    P8    27W / 350W |      6MiB / 24576MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:3B:00.0 Off |                  N/A |
| 30%   36C    P8    16W / 350W |      6MiB / 24576MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:86:00.0 Off |                  N/A |
|100%   78C    P2   339W / 350W |  19337MiB / 24576MiB |     98%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   2462439      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A   2462439      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A   2462439      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A   3780935      C   python                          19329MiB |
+-----------------------------------------------------------------------------+
[1m[7m%[27m[1m[0m                                                                                                                                                                                             k..ansUNet_Polyp\]633;D]633;P;Cwd=/home/zhangyanhua/Code_python/Project_TransUNet_My_Modified_V27_V1/TransUNet_Polyp[0m[27m[24m[J]633;A(base) 
[38;5;135mzhangyanhua[39m at [38;5;166m3090-xian[39m in [38;5;118m~/Code_python/Project_TransUNet_My_Modified_V27_V1/TransUNet_Polyp[39m 
$ ]633;B[K[?1h=[?2004hcconda activate yanhuazhang_mmlab[?1l>[?2004l
kconda\]633;C]633;E;conda activate yanhuazhang_mmlab[1m[7m%[27m[1m[0m                                                                                                                                                                                             k..ansUNet_Polyp\]633;D;0]633;P;Cwd=/home/zhangyanhua/Code_python/Project_TransUNet_My_Modified_V27_V1/TransUNet_Polyp[0m[27m[24m[J]633;A(yanhuazhang_mmlab) 
[38;5;135mzhangyanhua[39m at [38;5;166m3090-xian[39m in [38;5;118m~/Code_python/Project_TransUNet_My_Modified_V27_V1/TransUNet_Polyp[39m 
$ ]633;B[K[?1h=[?2004hCCUDA_VISIBLE_DEVICES=0 python train.py --dataset Synapse --Model_Name My_Model --Local_Global_fusion_method Attention_Gate --If_use_UNet_decoder False --is_deconv False --if_sum_fusion Tr [Kuue --If_Deep_Supervision True --bran_weights 0.4 0.3 0.2 0.1 --If_use_UNet_fusion_stage_features True --base_lr 0.1 --If_use_position_embedding True --name_position_method Sinusoid --If_in_ [Kddeep_sup True --If_out_side True --If_attention_scale False --If_backbone_use_Stoch_Depth False --If_remove_Norm False --If_remove_ReLU False --branch_depths 5 5 5 5 5 --branch_in_channels  [K2256 256 256 256 256 --branch_key_channels 32 32 32 32 32 --seed 1294[?1l>[?2004l
kpython\]633;C]633;E;CUDA_VISIBLE_DEVICES=0 python train.py --dataset Synapse --Model_Name My_Model --Local_Global_fusion_method Attention_Gate --If_use_UNet_decoder False --is_deconv False --if_sum_fusion True --If_Deep_Supervision True --bran_weights 0.4 0.3 0.2 0.1 --If_use_UNet_fusion_stage_features True --base_lr 0.1 --If_use_position_embedding True --name_position_method Sinusoid --If_in_deep_sup True --If_out_side True --If_attention_scale False --If_backbone_use_Stoch_Depth False --If_remove_Norm False --If_remove_ReLU False --branch_depths 5 5 5 5 5 --branch_in_channels 256 256 256 256 256 --branch_key_channels 32 32 32 32 32 --seed 1294[2023-07-05 16:16:04,422 INFO model_summary_GFLOPs_params_FPS_Use_argparse_V1.py line 29 3788455] FLOPs: 
/home/zhangyanhua/.conda/envs/yanhuazhang_mmlab/lib/python3.8/site-packages/torch/nn/functional.py:3454: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
Unsupported operator aten::max_pool2d encountered 1 time(s)
Unsupported operator aten::add_ encountered 16 time(s)
Unsupported operator aten::feature_dropout encountered 5 time(s)
Unsupported operator aten::add encountered 59 time(s)
Unsupported operator aten::mul encountered 48 time(s)
Unsupported operator aten::clone encountered 4 time(s)
Unsupported operator aten::softmax encountered 40 time(s)
Unsupported operator aten::sigmoid encountered 4 time(s)
Unsupported operator aten::expand_as encountered 4 time(s)
The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
branches_head.0, branches_head.0.0, branches_head.0.1, branches_head.1, branches_head.1.0, branches_head.1.1, branches_head.2, branches_head.2.0, branches_head.2.1, branches_head.3, branches_head.3.0, branches_head.3.1, trans.0.transformer_blocks.1.drop_path, trans.0.transformer_blocks.2.drop_path, trans.0.transformer_blocks.3.drop_path, trans.0.transformer_blocks.4.drop_path, trans.1.transformer_blocks.1.drop_path, trans.1.transformer_blocks.2.drop_path, trans.1.transformer_blocks.3.drop_path, trans.1.transformer_blocks.4.drop_path, trans.2.transformer_blocks.1.drop_path, trans.2.transformer_blocks.2.drop_path, trans.2.transformer_blocks.3.drop_path, trans.2.transformer_blocks.4.drop_path, trans.3.transformer_blocks.1.drop_path, trans.3.transformer_blocks.2.drop_path, trans.3.transformer_blocks.3.drop_path, trans.3.transformer_blocks.4.drop_path
[2023-07-05 16:16:05,777 INFO model_summary_GFLOPs_params_FPS_Use_argparse_V1.py line 30 3788455] 17144707300
[2023-07-05 16:16:05,777 INFO model_summary_GFLOPs_params_FPS_Use_argparse_V1.py line 31 3788455] --------------------------------
[2023-07-05 16:16:05,777 INFO model_summary_GFLOPs_params_FPS_Use_argparse_V1.py line 34 3788455] flops.by_operator: 
[2023-07-05 16:16:05,777 INFO model_summary_GFLOPs_params_FPS_Use_argparse_V1.py line 35 3788455] Counter({'conv': 16869290624, 'matmul': 174412800, 'batch_norm': 84604736, 'upsample_bilinear2d': 16399140})
[2023-07-05 16:16:05,777 INFO model_summary_GFLOPs_params_FPS_Use_argparse_V1.py line 36 3788455] --------------------------------
[2023-07-05 16:16:05,799 INFO model_summary_GFLOPs_params_FPS_Use_argparse_V1.py line 44 3788455] | name                                        | #elements or shape   |
|:--------------------------------------------|:---------------------|
| model                                       | 39.4M                |
|  layer0                                     |  0.1M                |
|   layer0.0                                  |   0.1M               |
|    layer0.0.0                               |    1.7K              |
|    layer0.0.1                               |    0.1K              |
|    layer0.0.3                               |    36.9K             |
|    layer0.0.4                               |    0.1K              |
|    layer0.0.6                               |    73.7K             |
|   layer0.1                                  |   0.3K               |
|    layer0.1.weight                          |    (128,)            |
|    layer0.1.bias                            |    (128,)            |
|  layer1                                     |  0.2M                |
|   layer1.0                                  |   0.2M               |
|    layer1.0.0                               |    95.5K             |
|    layer1.0.1                               |    70.4K             |
|    layer1.0.2                               |    70.4K             |
|  layer2                                     |  1.2M                |
|   layer2.0                                  |   1.2M               |
|    layer2.0.0                               |    0.4M              |
|    layer2.0.1                               |    0.3M              |
|    layer2.0.2                               |    0.3M              |
|    layer2.0.3                               |    0.3M              |
|  layer3                                     |  7.1M                |
|   layer3.0                                  |   7.1M               |
|    layer3.0.0                               |    1.5M              |
|    layer3.0.1                               |    1.1M              |
|    layer3.0.2                               |    1.1M              |
|    layer3.0.3                               |    1.1M              |
|    layer3.0.4                               |    1.1M              |
|    layer3.0.5                               |    1.1M              |
|  layer4                                     |  15.0M               |
|   layer4.0                                  |   15.0M              |
|    layer4.0.0                               |    6.0M              |
|    layer4.0.1                               |    4.5M              |
|    layer4.0.2                               |    4.5M              |
|  UNet_for_stage_features                    |  6.4M                |
|   UNet_for_stage_features.0                 |   4.5M               |
|    UNet_for_stage_features.0.channel_change |    2.1M              |
|    UNet_for_stage_features.0.conv           |    2.4M              |
|   UNet_for_stage_features.1                 |   1.3M               |
|    UNet_for_stage_features.1.channel_change |    0.1M              |
|    UNet_for_stage_features.1.conv           |    1.2M              |
|   UNet_for_stage_features.2                 |   0.7M               |
|    UNet_for_stage_features.2.channel_change |    66.0K             |
|    UNet_for_stage_features.2.conv           |    0.6M              |
|  top_branch_channel_change                  |  0.5M                |
|   top_branch_channel_change.0               |   0.5M               |
|    top_branch_channel_change.0.weight       |    (256, 2048, 1, 1) |
|   top_branch_channel_change.1               |   0.5K               |
|    top_branch_channel_change.1.weight       |    (256,)            |
|    top_branch_channel_change.1.bias         |    (256,)            |
|  position_embedding                         |  2.0K                |
|   position_embedding.0                      |   0.5K               |
|    position_embedding.0.2                   |    0.5K              |
|   position_embedding.1                      |   0.5K               |
|    position_embedding.1.2                   |    0.5K              |
|   position_embedding.2                      |   0.5K               |
|    position_embedding.2.2                   |    0.5K              |
|   position_embedding.3                      |   0.5K               |
|    position_embedding.3.2                   |    0.5K              |
|  trans                                      |  8.2M                |
|   trans.0                                   |   2.0M               |
|    trans.0.transformer_blocks               |    2.0M              |
|   trans.1                                   |   2.0M               |
|    trans.1.transformer_blocks               |    2.0M              |
|   trans.2                                   |   2.0M               |
|    trans.2.transformer_blocks               |    2.0M              |
|   trans.3                                   |   2.0M               |
|    trans.3.transformer_blocks               |    2.0M              |
|  local_global_Fusions                       |  0.5M                |
|   local_global_Fusions.0                    |   0.1M               |
|    local_global_Fusions.0.W                 |    66.3K             |
|    local_global_Fusions.0.theta             |    32.8K             |
|    local_global_Fusions.0.phi               |    32.9K             |
|    local_global_Fusions.0.psi               |    0.1K              |
|   local_global_Fusions.1                    |   0.1M               |
|    local_global_Fusions.1.W                 |    66.3K             |
|    local_global_Fusions.1.theta             |    32.8K             |
|    local_global_Fusions.1.phi               |    32.9K             |
|    local_global_Fusions.1.psi               |    0.1K              |
|   local_global_Fusions.2                    |   0.1M               |
|    local_global_Fusions.2.W                 |    66.3K             |
|    local_global_Fusions.2.theta             |    32.8K             |
|    local_global_Fusions.2.phi               |    32.9K             |
|    local_global_Fusions.2.psi               |    0.1K              |
|   local_global_Fusions.3                    |   0.1M               |
|    local_global_Fusions.3.W                 |    66.3K             |
|    local_global_Fusions.3.theta             |    32.8K             |
|    local_global_Fusions.3.phi               |    32.9K             |
|    local_global_Fusions.3.psi               |    0.1K              |
|  linear_fuse                                |  66.0K               |
|   linear_fuse.0                             |   65.5K              |
|    linear_fuse.0.weight                     |    (256, 256, 1, 1)  |
|   linear_fuse.1                             |   0.5K               |
|    linear_fuse.1.weight                     |    (256,)            |
|    linear_fuse.1.bias                       |    (256,)            |
|  seg_head                                   |  2.3K                |
|   seg_head.0                                |   2.3K               |
|    seg_head.0.weight                        |    (9, 256, 1, 1)    |
|    seg_head.0.bias                          |    (9,)              |
|  branches_head                              |  9.3K                |
|   branches_head.0                           |   2.3K               |
|    branches_head.0.1                        |    2.3K              |
|   branches_head.1                           |   2.3K               |
|    branches_head.1.1                        |    2.3K              |
|   branches_head.2                           |   2.3K               |
|    branches_head.2.1                        |    2.3K              |
|   branches_head.3                           |   2.3K               |
|    branches_head.3.1                        |    2.3K              |
[2023-07-05 16:16:05,799 INFO model_summary_backbone.py line 34 3788455] backbone name：My_Model: 
[2023-07-05 16:16:05,799 INFO model_summary_backbone.py line 35 3788455] My_Model(
  (layer0): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Identity()
  )
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (1): Dropout2d(p=0.2, inplace=False)
  )
  (layer2): Sequential(
    (0): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (1): Dropout2d(p=0.2, inplace=False)
  )
  (layer3): Sequential(
    (0): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (1): Dropout2d(p=0.2, inplace=False)
  )
  (layer4): Sequential(
    (0): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (1): Dropout2d(p=0.2, inplace=False)
  )
  (UNet_for_stage_features): ModuleList(
    (0): unetUp(
      (channel_change): Sequential(
        (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (conv): unetConv2(
        (conv1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (dropout): Identity()
    )
    (1): unetUp(
      (channel_change): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (conv): unetConv2(
        (conv1): Sequential(
          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (dropout): Identity()
    )
    (2): unetUp(
      (channel_change): Sequential(
        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (conv): unetConv2(
        (conv1): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (dropout): Identity()
    )
  )
  (top_branch_channel_change): Sequential(
    (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (position_embedding): ModuleList(
    (0): Sequential(
      (0): Pos_Embed_Sinusoid()
      (1): Identity()
      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Sequential(
      (0): Pos_Embed_Sinusoid()
      (1): Identity()
      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Sequential(
      (0): Pos_Embed_Sinusoid()
      (1): Identity()
      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): Sequential(
      (0): Pos_Embed_Sinusoid()
      (1): Identity()
      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (trans): ModuleList(
    (0): BasicLayer_Share_spatial_reduction(
      (transformer_blocks): ModuleList(
        (0): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): Identity()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (1): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (2): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (3): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (4): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
      )
    )
    (1): BasicLayer_Share_spatial_reduction(
      (transformer_blocks): ModuleList(
        (0): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): Identity()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (1): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (2): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (3): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (4): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
      )
    )
    (2): BasicLayer_Share_spatial_reduction(
      (transformer_blocks): ModuleList(
        (0): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): Identity()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (1): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (2): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (3): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (4): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
      )
    )
    (3): BasicLayer_Share_spatial_reduction(
      (transformer_blocks): ModuleList(
        (0): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): Identity()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (1): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (2): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (3): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
        (4): Block_Spatial_Battleneck_Share_spatial_reduction(
          (attn): efficient_Attention_modified_Param_sharing_Share_spatial_reduction(
            (to_q): Conv2d_BN(
              (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (to_kv): Conv2d_BN(
              (c): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (proj): Sequential(
              (0): ReLU()
              (1): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (drop_path): DropPath()
          (mlp): Mlp(
            (fc1): Conv2d_BN(
              (c): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (act): ReLU()
            (fc2): Conv2d_BN(
              (c): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (drop): Identity()
          )
        )
      )
    )
  )
  (local_global_Fusions): ModuleList(
    (0): GridAttentionBlock2D(
      (W): Sequential(
        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (theta): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (phi): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (psi): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): GridAttentionBlock2D(
      (W): Sequential(
        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (theta): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (phi): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (psi): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): GridAttentionBlock2D(
      (W): Sequential(
        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (theta): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (phi): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (psi): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): GridAttentionBlock2D(
      (W): Sequential(
        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (theta): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (phi): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (psi): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (local_global_Fusions_drop): ModuleList(
    (0): Identity()
    (1): Identity()
    (2): Identity()
    (3): Identity()
  )
  (linear_fuse): Sequential(
    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout2d(p=0.1, inplace=False)
  )
  (seg_head): Sequential(
    (0): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))
  )
  (branches_head): ModuleList(
    (0): Sequential(
      (0): Dropout2d(p=0.1, inplace=False)
      (1): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): Sequential(
      (0): Dropout2d(p=0.1, inplace=False)
      (1): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): Sequential(
      (0): Dropout2d(p=0.1, inplace=False)
      (1): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): Sequential(
      (0): Dropout2d(p=0.1, inplace=False)
      (1): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[2023-07-05 16:16:05,809 INFO model_summary_backbone.py line 36 3788455] -----------------------------------------------------------------------------
[2023-07-05 16:16:05,809 INFO model_summary_backbone.py line 37 3788455]    
Namespace(Drop_path_rate_Trans=None, Dropout_Rate_CNN=None, Dropout_Rate_Local_Global_Fusion=None, Dropout_Rate_Multi_branch_fusion=0.1, Dropout_Rate_Pos=None, Dropout_Rate_SegHead=0.1, Dropout_Rate_Trans=0, Dropout_Rate_UNet=None, If_Deep_Supervision=True, If_Local_GLobal_Fuison=True, If_Multiscale_Train=True, If_attention_scale=False, If_backbone_use_Stoch_Depth=False, If_binary_prediction=False, If_efficient_attention=True, If_in_deep_sup=True, If_out_side=True, If_pretrained=True, If_remove_Norm=False, If_remove_ReLU=False, If_use_UNet_decoder=False, If_use_UNet_fusion_stage_features=True, If_use_position_embedding=True, If_weight_init=False, Local_Global_fusion_method='Attention_Gate', Model_Name='My_Model', Multi_branch_concat_fusion=False, Scale_Choose='Scale_L', backbone='resnet50_SFNet', base_lr=0.1, batch_size=24, bran_weights=[0.4, 0.3, 0.2, 0.1], branch_choose=None, branch_depths=[5, 5, 5, 5, 5], branch_in_channels=[256, 256, 256, 256, 256], branch_key_channels=[32, 32, 32, 32, 32], branch_num_heads=None, branch_out_channels=None, dataset='Synapse', deterministic=1, exp='My_Model_Synapse224', grad_clip=0.5, if_sum_fusion=True, img_size=224, img_size_width=224, is_deconv=False, is_pretrain=True, list_dir='./lists/lists_Synapse', loss_name='ce_dice_loss', max_epochs=150, max_iterations=30000, n_gpu=1, name_position_method='Sinusoid', num_classes=9, one_kv_head=True, optimizer='SGD', root_path='/home/zhangyanhua/Code_python/Dataset/Medical_Dataset/Synapse/train_npz', seed=1294, share_kv=True, use_dilation=False)
The length of train set is: 2211
93 iterations per epoch. 13950 max iterations 
  0%|                                         | 0/150 [00:00<?, ?it/s]/home/zhangyanhua/.conda/envs/yanhuazhang_mmlab/lib/python3.8/site-packages/torch/nn/functional.py:3454: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
iteration 1 : loss : 3.025965, loss_ce: 1.980258
iteration 2 : loss : 2.174502, loss_ce: 0.762340
iteration 3 : loss : 1.629617, loss_ce: 0.357171
iteration 4 : loss : 1.465998, loss_ce: 0.445175
iteration 5 : loss : 1.401913, loss_ce: 0.532403
iteration 6 : loss : 1.168173, loss_ce: 0.283826
iteration 7 : loss : 1.269390, loss_ce: 0.441765
iteration 8 : loss : 1.239864, loss_ce: 0.398463
^C  0%|                                         | 0/150 [00:06<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 625, in <module>
    trainer[dataset_name](args, net.cuda(), Log_path, TensorboardX_path, Model_path) # 重新把 net 放到 cuda 上。
  File "/home/zhangyanhua/Code_python/Project_TransUNet_My_Modified_V27_V1/TransUNet_Polyp/trainer.py", line 99, in trainer_synapse
    optimizer.step()
  File "/home/zhangyanhua/.conda/envs/yanhuazhang_mmlab/lib/python3.8/site-packages/torch/optim/optimizer.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangyanhua/.conda/envs/yanhuazhang_mmlab/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/zhangyanhua/.conda/envs/yanhuazhang_mmlab/lib/python3.8/site-packages/torch/optim/sgd.py", line 110, in step
    F.sgd(params_with_grad,
  File "/home/zhangyanhua/.conda/envs/yanhuazhang_mmlab/lib/python3.8/site-packages/torch/optim/_functional.py", line 176, in sgd
    param.add_(d_p, alpha=-lr)
KeyboardInterrupt

[1m[7m%[27m[1m[0m                                                                                                                                                                                             k..ansUNet_Polyp\]633;D;130]633;P;Cwd=/home/zhangyanhua/Code_python/Project_TransUNet_My_Modified_V27_V1/TransUNet_Polyp[0m[27m[24m[J]633;A(yanhuazhang_mmlab) 
[38;5;135mzhangyanhua[39m at [38;5;166m3090-xian[39m in [38;5;118m~/Code_python/Project_TransUNet_My_Modified_V27_V1/TransUNet_Polyp[39m 
$ ]633;B[K[?1h=[?2004h[A[A[0m[27m[24m[J]633;A(yanhuazhang_mmlab) 
[38;5;135mzhangyanhua[39m at [38;5;166m3090-xian[39m in [38;5;118m~/Code_python/Project_TransUNet_My_Modified_V27_V1/TransUNet_Polyp[39m 
$ ]633;B[?2004l

Script done on 2023-07-05 16:31:06+08:00 [COMMAND_EXIT_CODE="130"]
